{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Generation with `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "OPEN_AI_KEY = os.environ.get('OPEN_AI_KEY')\n",
    "client = OpenAI(api_key=OPEN_AI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a system that can generate chat prompts that understands values in Chinese communication. This includes indirect communication, which relies on subtlety and hints and context, as well as showing respect in front of elders, as well as humility. \"},\n",
    "    {\"role\": \"system\", \"content\": \"Here are 3 examples: Input:\\nCONTEXT: You are a caregiver in a nursing home, conversing with an elderly Chinese resident, Mrs. Li, in English. You notice she hasn't finished her food from yesterday.\\n Mrs. Li: Hello!\\n Response:\\n Hello Mrs. Li. Was the food from yesterday to your liking?\\n \\n Input:\\n CONTEXT: You are a hotel receptionist, speaking to an elderly Chinese couple that is checking out. They have not paid yet, but are insisting they have. \\n Woman: We would like to check out, we paid yesterday.\\n Response:\\n I apologize if there's been a misunderstanding. I will double check our system again.\\n \\n Input:\\n CONTEXT: You are conversing with a Chinese coworker to provide feedback on their work, which is a little lacking. \\n Coworker: Hello!\\n Response:\\n Hello, how are you? I've reviewed your work. It's quite comprehensive. Would you like to go over this section though?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Give me 40 chat prompts of unique scenarios that exhibit values in Chinese communication, especially the values of indirectness and respect to elders. Use the format of the examples given with the context.\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write samples to data file (appending)\n",
    "with open('data/gpt_samples.txt', 'a') as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sample_files(file):\n",
    "    f = open(file, \"r\")\n",
    "    is_question = False\n",
    "    prompts = []\n",
    "    ideal = []\n",
    "    for x in f: \n",
    "        x = x.strip()\n",
    "        if \"CONTEXT: \" in x:\n",
    "            i = x.index(\"CONTEXT: \")\n",
    "            cur_prompt = x[i+9:]\n",
    "            is_question = True\n",
    "\n",
    "        elif is_question:\n",
    "            cur_prompt += \"\\n\" + x\n",
    "            is_question = False\n",
    "            prompts.append(cur_prompt)\n",
    "        \n",
    "        elif \"Response: \" in x:\n",
    "            resp = x.strip().replace(\"Response: \",\"\")\n",
    "            ideal.append(resp)\n",
    "    f.close()\n",
    "    return prompts, ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse nursing home prompts and general prompts\n",
    "nh_prompts, nh_ideal = parse_sample_files(\"data/gpt_samples_nh.txt\")\n",
    "gen_prompts, gen_ideal = parse_sample_files(\"data/gpt_samples_gen.txt\")\n",
    "\n",
    "# Concatenate prompts\n",
    "all_prompts = nh_prompts + gen_prompts\n",
    "all_ideal = nh_ideal + gen_ideal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Llama2 prompt template format to all examples\n",
    "\n",
    "cncomm = []\n",
    "bos_token = \"<s>\"\n",
    "eos_token = \"</s>\"\n",
    "sys_info = \"You are a system that is able to adapt to different scenarios and provide English responses that are culturally sensitive to values in Chinese communication. These values include indirect communication, which relies on subtlety and hints and context, as well as showing respect in front of elders, and maintaining humility.\"\n",
    "for ex in zip(all_prompts,all_ideal): \n",
    "    prompt = f\"{bos_token}[INST]\\n<<SYS>>{sys_info}<</SYS>>\\n{ex[0]}\\n[/INST]\\n{ex[1]}{eos_token}\"\n",
    "    cncomm.append([prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cncomm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"samples\"]\n",
    "with open('data/cn_comm.csv', 'w') as f:\n",
    "     \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "     \n",
    "    write.writerow(fields)\n",
    "    write.writerows(cncomm)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
